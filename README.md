# **End-to-End Machine Learning Project with AWS Deployment**  

### ğŸš€ **Overview**  
This project implements an **end-to-end machine learning pipeline** that includes **data ingestion, transformation, model training, and prediction**. The trained models are deployed using **Flask**, and the entire workflow is containerized using **Docker**. The CI/CD pipeline is automated via **GitHub Actions**, which builds the Docker image and pushes it to **AWS Elastic Container Registry (ECR)** before deploying it on an **AWS EC2 instance**.  

---

## ğŸ“‚ **Project Structure**  

```
ğŸ“¦ ML_Project
â”‚-- ğŸ“œ README.md
â”‚-- ğŸ“œ Dockerfile  # Docker container setup
â”‚-- ğŸ“œ setup.py  # Package setup
â”‚-- ğŸ“œ requirements.txt  # Dependencies
â”‚-- ğŸ“‚ workflows/  # GitHub Actions for CI/CD
â”‚   â””â”€â”€ main.yaml  # Workflow for Docker build and AWS deployment
â”‚-- ğŸ“‚ artifacts/  # Stored training artifacts
â”‚   â”‚-- train.csv
â”‚   â”‚-- test.csv
â”‚   â”‚-- data.csv
â”‚   â”‚-- model.pkl
â”‚   â””â”€â”€ preprocessor.pkl
â”‚-- ğŸ“‚ notebook/  # Jupyter Notebook with model training results
â”‚   â”‚-- MODEL_TRAINING.ipynb
â”‚   â”‚-- catboost_info/
â”‚   â””â”€â”€ data/  # Raw dataset
â”‚-- ğŸ“‚ src/  # Main source code
â”‚   â”‚-- logger.py  # Logging utility
â”‚   â”‚-- utils.py  # Helper functions
â”‚   â””â”€â”€ components/
â”‚       â”‚-- data_ingestion.py
â”‚       â”‚-- data_transformation.py
â”‚       â””â”€â”€ model_trainer.py
â”‚-- ğŸ“‚ pipeline/  # Model inference pipeline
â”‚   â””â”€â”€ predict_pipeline.py
â”‚-- ğŸ“‚ templates/  # Flask Web UI
â”‚   â”‚-- home.html
â”‚   â””â”€â”€ index.html
```

---

## âš™ï¸ **Machine Learning Models Implemented**  
The project trains multiple **regression models** and evaluates them using **RÂ² scores**:  

```python
models = {
    "Linear Regression": LinearRegression(),
    "Lasso": Lasso(),
    "Ridge": Ridge(),
    "K-Neighbors Regressor": KNeighborsRegressor(),
    "Decision Tree": DecisionTreeRegressor(),
    "Random Forest Regressor": RandomForestRegressor(),
    "XGBRegressor": XGBRegressor(), 
    "CatBoosting Regressor": CatBoostRegressor(verbose=False),
    "AdaBoost Regressor": AdaBoostRegressor()
}
```

- The models are trained and stored as **model.pkl** along with **preprocessor.pkl** for data transformation.  
- Performance evaluation metrics like **RÂ² score** are stored for comparison.  

---

## ğŸŒ **Flask Web App Usage**  
1. **Run Flask Application**  
   ```bash
   python app.py
   ```
2. Open **http://localhost:5000/** in the browser.  
3. **Navigate to Prediction Page**  
   - After loading the home page, manually enter `/predictdata` in the URL.  
   - Enter feature values to get predictions.  

---

## ğŸ³ **Docker Setup & Deployment on AWS**  

### **1ï¸âƒ£ Docker Build & Push to AWS ECR**  
```bash
# Build Docker Image
docker build -t simple-app .

# Authenticate Docker with AWS ECR
aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin 566373416292.dkr.ecr.ap-south-1.amazonaws.com

# Tag Docker Image
docker tag simple-app:latest 566373416292.dkr.ecr.ap-south-1.amazonaws.com/simple-app:latest

# Push Image to ECR
docker push 566373416292.dkr.ecr.ap-south-1.amazonaws.com/simple-app:latest
```

### **2ï¸âƒ£ Run Docker Container on AWS EC2**  
```bash
# SSH into EC2
ssh -i "your-key.pem" ubuntu@your-ec2-ip

# Update and Install Docker (Required)
sudo apt-get update -y
sudo apt-get upgrade -y
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh
sudo usermod -aG docker ubuntu
newgrp docker

# Run Docker Container
docker run -d -p 5000:5000 566373416292.dkr.ecr.ap-south-1.amazonaws.com/simple-app:latest
```

---

## ğŸ¤– **GitHub Actions - CI/CD Workflow**  

The **GitHub Actions workflow** automates:  
âœ… **Building the Docker image**  
âœ… **Pushing it to AWS ECR**  
âœ… **Deploying it on EC2**  

ğŸ“Œ **Setup GitHub Secrets:**  
- **AWS_ACCESS_KEY_ID**  
- **AWS_SECRET_ACCESS_KEY**  
- **AWS_REGION** = `us-east-1`  
- **AWS_ECR_LOGIN_URI** = `566373416292.dkr.ecr.ap-south-1.amazonaws.com`  
- **ECR_REPOSITORY_NAME** = `simple-app`  

ğŸ“Œ **Workflow File: `workflows/main.yaml`**  
```yaml
name: Build and Deploy ML Model

on:
  push:
    branches:
      - main

jobs:
  build:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout Code
        uses: actions/checkout@v2

      - name: Login to AWS ECR
        run: |
          aws ecr get-login-password --region ${{ secrets.AWS_REGION }} | docker login --username AWS --password-stdin ${{ secrets.AWS_ECR_LOGIN_URI }}

      - name: Build Docker Image
        run: docker build -t ${{ secrets.ECR_REPOSITORY_NAME }} .

      - name: Tag Docker Image
        run: docker tag ${{ secrets.ECR_REPOSITORY_NAME }}:latest ${{ secrets.AWS_ECR_LOGIN_URI }}/${{ secrets.ECR_REPOSITORY_NAME }}:latest

      - name: Push Docker Image to AWS ECR
        run: docker push ${{ secrets.AWS_ECR_LOGIN_URI }}/${{ secrets.ECR_REPOSITORY_NAME }}:latest
```

---

## ğŸ— **Project Setup (Local Execution)**  

### **1ï¸âƒ£ Clone the Repository**  
```bash
git clone https://github.com/Koushik7893/End-to-End-Machine-Learning-Project-with-AWS-Deployment
cd End-to-End-Machine-Learning-Project-with-AWS-Deployment
```

### **2ï¸âƒ£ Install Dependencies**  
```bash
pip install -r requirements.txt
```

### **3ï¸âƒ£ Train & Evaluate Models**  
```bash
python src/components/model_trainer.py
```

### **4ï¸âƒ£ Run Flask App**  
```bash
python app.py
```

---

## ğŸ“Œ **Technologies Used**  
- **Python**  
- **Flask** (Web Framework)  
- **Docker** (Containerization)  
- **AWS ECR & EC2** (Cloud Deployment)  
- **GitHub Actions** (CI/CD Pipeline)  
- **Machine Learning Libraries**:  
  - **Scikit-Learn** (Linear Regression, Decision Trees, Random Forest, etc.)  
  - **XGBoost & CatBoost** (Boosting Models)  
  - **Pandas, NumPy** (Data Processing)  

---

## ğŸ”® **Future Enhancements**  
- Deploying as a **serverless API using AWS Lambda**.  
- Adding **monitoring & logging** with AWS CloudWatch.  
- Implementing **feature engineering & hyperparameter tuning**.  

---

## ğŸ¤ **Contributing**  
Contributions are welcome! Feel free to **fork**, **create a pull request**, or open an **issue**.  

---

## ğŸ“œ **License**  
This project is **open-source** under the **Apache License**.  

---

### ğŸ¯ **Final Thoughts**  
This project showcases **ML model training, deployment, and automation with AWS and Docker**. It provides a robust **CI/CD pipeline** via **GitHub Actions** to streamline deployment. ğŸš€  
